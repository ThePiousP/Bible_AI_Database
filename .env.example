# Bible AI Database API Configuration
# Copy this file to .env and update with your values

# API Configuration
API_HOST=127.0.0.1
API_PORT=8000
API_WORKERS=4
API_RELOAD=false

# CORS - Allowed Origins (comma-separated)
# Use * for development, specify exact origins in production
# Example: https://myapp.com,https://app.myapp.com
ALLOWED_ORIGINS=*

# Database
DATABASE_PATH=data/GoodBook.db

# API Keys
# Add your API keys here (for production, use a proper key management system)
# Format: KEY_NAME=actual_key_value
# These are loaded by the API key manager

# Rate Limiting
DEFAULT_RATE_LIMIT=100  # requests per minute
ANON_RATE_LIMIT=10      # requests per minute for unauthenticated requests

# AI Model Configuration
LLM_PROVIDER=openai
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_MODEL=gpt-4
OPENAI_TEMPERATURE=0.7
OPENAI_MAX_TOKENS=500

# Alternative: Use local models
# LLM_PROVIDER=huggingface
# HF_MODEL=facebook/opt-1.3b

# Embeddings
EMBEDDINGS_MODEL=all-mpnet-base-v2
EMBEDDINGS_PATH=embeddings/bible_embeddings.pkl
EMBEDDINGS_BATCH_SIZE=32

# RAG Configuration
RAG_TOP_K=10
RAG_SIMILARITY_THRESHOLD=0.3
RAG_USE_RERANKING=false

# Logging
LOG_LEVEL=INFO
LOG_FILE=logs/api.log

# Security
# Secret key for JWT tokens (if implementing session-based auth in future)
SECRET_KEY=your-secret-key-here-change-in-production

# Redis (for distributed rate limiting in production)
# REDIS_URL=redis://localhost:6379/0

# Monitoring (optional)
# SENTRY_DSN=your_sentry_dsn_here
# PROMETHEUS_ENABLED=true
